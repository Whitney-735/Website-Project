{
  "articles": [
    {
      "path": "about.html",
      "title": "About",
      "author": [],
      "contents": "\nAbout Me\nI am currently a graduate student at Mississippi State University in MPA program. After graduating in May 2022, I will start working for Deloitte as Tax Consultant. Currently, I am studying CPA financial exam and planning to take it during this winter break. Wish me luck!\nAbout this Site\nOn this website, you will find my resume and the projects that I have done in Data Analytics Class. Feel free to check out another time to see my updates.\n\n\n\n",
      "last_modified": "2021-12-08T21:37:42-06:00"
    },
    {
      "path": "Final.html",
      "title": "Support Vector Machines",
      "description": "Classifying the type of wine using Support Vector Machine Learning\n",
      "author": [],
      "contents": "\n\nContents\nWhat is SVM\nData used in SVM\nData Statistics\nOverview of wine data set\nProcess the wine data\nVerify my assumption\n\nSVM Applications\n\nWhat is SVM\nSupport Vector Machine is a supervised machine learning algorithm capable of performing classification, regression, and even outlier detection1. It will draw a line that separates two classes of variables in order to determine the character of predicting variables. Here, I am going to use SVM Linear to predict the type of wine based on the variables provided in the data set.\nData used in SVM\nThe data I am using is found from UCI website2 where provides many data sets that can be used for analysis purpose. I choose wine data set for this project to predict the class of wine using the collected variables. There are 13 variables used to classify the class of wine.\nData Statistics\nOverview of wine data set\n\n'data.frame':   177 obs. of  15 variables:\n $ Class               : chr  \"1\" \"1\" \"1\" \"1\" ...\n $ Alcohol             : num  13.2 13.2 14.4 13.2 14.2 ...\n $ Malic.acid          : num  1.78 2.36 1.95 2.59 1.76 1.87 2.15 1.64 1.35 2.16 ...\n $ Ash                 : num  2.14 2.67 2.5 2.87 2.45 2.45 2.61 2.17 2.27 2.3 ...\n $ Alcalinity.of.ash   : num  11.2 18.6 16.8 21 15.2 14.6 17.6 14 16 18 ...\n $ Magnesium           : num  100 101 113 118 112 96 121 97 98 105 ...\n $ Total.phenols       : num  2.65 2.8 3.85 2.8 3.27 2.5 2.6 2.8 2.98 2.95 ...\n $ Flavanoids          : num  2.76 3.24 3.49 2.69 3.39 2.52 2.51 2.98 3.15 3.32 ...\n $ Nonflavanoid.phenols: num  0.26 0.3 0.24 0.39 0.34 0.3 0.31 0.29 0.22 0.22 ...\n $ Proanthocyanins     : num  1.28 2.81 2.18 1.82 1.97 1.98 1.25 1.98 1.85 2.38 ...\n $ Color.intensity     : num  4.38 5.68 7.8 4.32 6.75 5.25 5.05 5.2 7.22 5.75 ...\n $ Hue                 : num  1.05 1.03 0.86 1.04 1.05 1.02 1.06 1.08 1.01 1.25 ...\n $ diluted.wines       : num  3.4 3.17 3.45 2.93 2.85 3.58 3.58 2.85 3.55 3.17 ...\n $ Proline             : num  1050 1185 1480 735 1450 ...\n $ class               : chr  \"One\" \"One\" \"One\" \"One\" ...\n\n\nClass\n\n\nAlcohol\n\n\nMalic.acid\n\n\nAsh\n\n\nAlcalinity.of.ash\n\n\nMagnesium\n\n\nTotal.phenols\n\n\nFlavanoids\n\n\nNonflavanoid.phenols\n\n\nProanthocyanins\n\n\nColor.intensity\n\n\nHue\n\n\ndiluted.wines\n\n\nProline\n\n\nclass\n\n\n1\n\n\n13.20\n\n\n1.78\n\n\n2.14\n\n\n11.2\n\n\n100\n\n\n2.65\n\n\n2.76\n\n\n0.26\n\n\n1.28\n\n\n4.380000\n\n\n1.050\n\n\n3.40\n\n\n1050\n\n\nOne\n\n\n1\n\n\n13.16\n\n\n2.36\n\n\n2.67\n\n\n18.6\n\n\n101\n\n\n2.80\n\n\n3.24\n\n\n0.30\n\n\n2.81\n\n\n5.680000\n\n\n1.030\n\n\n3.17\n\n\n1185\n\n\nOne\n\n\n1\n\n\n14.37\n\n\n1.95\n\n\n2.50\n\n\n16.8\n\n\n113\n\n\n3.85\n\n\n3.49\n\n\n0.24\n\n\n2.18\n\n\n7.800000\n\n\n0.860\n\n\n3.45\n\n\n1480\n\n\nOne\n\n\n1\n\n\n13.24\n\n\n2.59\n\n\n2.87\n\n\n21.0\n\n\n118\n\n\n2.80\n\n\n2.69\n\n\n0.39\n\n\n1.82\n\n\n4.320000\n\n\n1.040\n\n\n2.93\n\n\n735\n\n\nOne\n\n\n1\n\n\n14.20\n\n\n1.76\n\n\n2.45\n\n\n15.2\n\n\n112\n\n\n3.27\n\n\n3.39\n\n\n0.34\n\n\n1.97\n\n\n6.750000\n\n\n1.050\n\n\n2.85\n\n\n1450\n\n\nOne\n\n\n1\n\n\n14.39\n\n\n1.87\n\n\n2.45\n\n\n14.6\n\n\n96\n\n\n2.50\n\n\n2.52\n\n\n0.30\n\n\n1.98\n\n\n5.250000\n\n\n1.020\n\n\n3.58\n\n\n1290\n\n\nOne\n\n\n1\n\n\n14.06\n\n\n2.15\n\n\n2.61\n\n\n17.6\n\n\n121\n\n\n2.60\n\n\n2.51\n\n\n0.31\n\n\n1.25\n\n\n5.050000\n\n\n1.060\n\n\n3.58\n\n\n1295\n\n\nOne\n\n\n1\n\n\n14.83\n\n\n1.64\n\n\n2.17\n\n\n14.0\n\n\n97\n\n\n2.80\n\n\n2.98\n\n\n0.29\n\n\n1.98\n\n\n5.200000\n\n\n1.080\n\n\n2.85\n\n\n1045\n\n\nOne\n\n\n1\n\n\n13.86\n\n\n1.35\n\n\n2.27\n\n\n16.0\n\n\n98\n\n\n2.98\n\n\n3.15\n\n\n0.22\n\n\n1.85\n\n\n7.220000\n\n\n1.010\n\n\n3.55\n\n\n1045\n\n\nOne\n\n\n1\n\n\n14.10\n\n\n2.16\n\n\n2.30\n\n\n18.0\n\n\n105\n\n\n2.95\n\n\n3.32\n\n\n0.22\n\n\n2.38\n\n\n5.750000\n\n\n1.250\n\n\n3.17\n\n\n1510\n\n\nOne\n\n\n1\n\n\n14.12\n\n\n1.48\n\n\n2.32\n\n\n16.8\n\n\n95\n\n\n2.20\n\n\n2.43\n\n\n0.26\n\n\n1.57\n\n\n5.000000\n\n\n1.170\n\n\n2.82\n\n\n1280\n\n\nOne\n\n\n1\n\n\n13.75\n\n\n1.73\n\n\n2.41\n\n\n16.0\n\n\n89\n\n\n2.60\n\n\n2.76\n\n\n0.29\n\n\n1.81\n\n\n5.600000\n\n\n1.150\n\n\n2.90\n\n\n1320\n\n\nOne\n\n\n1\n\n\n14.75\n\n\n1.73\n\n\n2.39\n\n\n11.4\n\n\n91\n\n\n3.10\n\n\n3.69\n\n\n0.43\n\n\n2.81\n\n\n5.400000\n\n\n1.250\n\n\n2.73\n\n\n1150\n\n\nOne\n\n\n1\n\n\n14.38\n\n\n1.87\n\n\n2.38\n\n\n12.0\n\n\n102\n\n\n3.30\n\n\n3.64\n\n\n0.29\n\n\n2.96\n\n\n7.500000\n\n\n1.200\n\n\n3.00\n\n\n1547\n\n\nOne\n\n\n1\n\n\n13.63\n\n\n1.81\n\n\n2.70\n\n\n17.2\n\n\n112\n\n\n2.85\n\n\n2.91\n\n\n0.30\n\n\n1.46\n\n\n7.300000\n\n\n1.280\n\n\n2.88\n\n\n1310\n\n\nOne\n\n\n1\n\n\n14.30\n\n\n1.92\n\n\n2.72\n\n\n20.0\n\n\n120\n\n\n2.80\n\n\n3.14\n\n\n0.33\n\n\n1.97\n\n\n6.200000\n\n\n1.070\n\n\n2.65\n\n\n1280\n\n\nOne\n\n\n1\n\n\n13.83\n\n\n1.57\n\n\n2.62\n\n\n20.0\n\n\n115\n\n\n2.95\n\n\n3.40\n\n\n0.40\n\n\n1.72\n\n\n6.600000\n\n\n1.130\n\n\n2.57\n\n\n1130\n\n\nOne\n\n\n1\n\n\n14.19\n\n\n1.59\n\n\n2.48\n\n\n16.5\n\n\n108\n\n\n3.30\n\n\n3.93\n\n\n0.32\n\n\n1.86\n\n\n8.700000\n\n\n1.230\n\n\n2.82\n\n\n1680\n\n\nOne\n\n\n1\n\n\n13.64\n\n\n3.10\n\n\n2.56\n\n\n15.2\n\n\n116\n\n\n2.70\n\n\n3.03\n\n\n0.17\n\n\n1.66\n\n\n5.100000\n\n\n0.960\n\n\n3.36\n\n\n845\n\n\nOne\n\n\n1\n\n\n14.06\n\n\n1.63\n\n\n2.28\n\n\n16.0\n\n\n126\n\n\n3.00\n\n\n3.17\n\n\n0.24\n\n\n2.10\n\n\n5.650000\n\n\n1.090\n\n\n3.71\n\n\n780\n\n\nOne\n\n\n1\n\n\n12.93\n\n\n3.80\n\n\n2.65\n\n\n18.6\n\n\n102\n\n\n2.41\n\n\n2.41\n\n\n0.25\n\n\n1.98\n\n\n4.500000\n\n\n1.030\n\n\n3.52\n\n\n770\n\n\nOne\n\n\n1\n\n\n13.71\n\n\n1.86\n\n\n2.36\n\n\n16.6\n\n\n101\n\n\n2.61\n\n\n2.88\n\n\n0.27\n\n\n1.69\n\n\n3.800000\n\n\n1.110\n\n\n4.00\n\n\n1035\n\n\nOne\n\n\n1\n\n\n12.85\n\n\n1.60\n\n\n2.52\n\n\n17.8\n\n\n95\n\n\n2.48\n\n\n2.37\n\n\n0.26\n\n\n1.46\n\n\n3.930000\n\n\n1.090\n\n\n3.63\n\n\n1015\n\n\nOne\n\n\n1\n\n\n13.50\n\n\n1.81\n\n\n2.61\n\n\n20.0\n\n\n96\n\n\n2.53\n\n\n2.61\n\n\n0.28\n\n\n1.66\n\n\n3.520000\n\n\n1.120\n\n\n3.82\n\n\n845\n\n\nOne\n\n\n1\n\n\n13.05\n\n\n2.05\n\n\n3.22\n\n\n25.0\n\n\n124\n\n\n2.63\n\n\n2.68\n\n\n0.47\n\n\n1.92\n\n\n3.580000\n\n\n1.130\n\n\n3.20\n\n\n830\n\n\nOne\n\n\n1\n\n\n13.39\n\n\n1.77\n\n\n2.62\n\n\n16.1\n\n\n93\n\n\n2.85\n\n\n2.94\n\n\n0.34\n\n\n1.45\n\n\n4.800000\n\n\n0.920\n\n\n3.22\n\n\n1195\n\n\nOne\n\n\n1\n\n\n13.30\n\n\n1.72\n\n\n2.14\n\n\n17.0\n\n\n94\n\n\n2.40\n\n\n2.19\n\n\n0.27\n\n\n1.35\n\n\n3.950000\n\n\n1.020\n\n\n2.77\n\n\n1285\n\n\nOne\n\n\n1\n\n\n13.87\n\n\n1.90\n\n\n2.80\n\n\n19.4\n\n\n107\n\n\n2.95\n\n\n2.97\n\n\n0.37\n\n\n1.76\n\n\n4.500000\n\n\n1.250\n\n\n3.40\n\n\n915\n\n\nOne\n\n\n1\n\n\n14.02\n\n\n1.68\n\n\n2.21\n\n\n16.0\n\n\n96\n\n\n2.65\n\n\n2.33\n\n\n0.26\n\n\n1.98\n\n\n4.700000\n\n\n1.040\n\n\n3.59\n\n\n1035\n\n\nOne\n\n\n1\n\n\n13.73\n\n\n1.50\n\n\n2.70\n\n\n22.5\n\n\n101\n\n\n3.00\n\n\n3.25\n\n\n0.29\n\n\n2.38\n\n\n5.700000\n\n\n1.190\n\n\n2.71\n\n\n1285\n\n\nOne\n\n\n1\n\n\n13.58\n\n\n1.66\n\n\n2.36\n\n\n19.1\n\n\n106\n\n\n2.86\n\n\n3.19\n\n\n0.22\n\n\n1.95\n\n\n6.900000\n\n\n1.090\n\n\n2.88\n\n\n1515\n\n\nOne\n\n\n1\n\n\n13.68\n\n\n1.83\n\n\n2.36\n\n\n17.2\n\n\n104\n\n\n2.42\n\n\n2.69\n\n\n0.42\n\n\n1.97\n\n\n3.840000\n\n\n1.230\n\n\n2.87\n\n\n990\n\n\nOne\n\n\n1\n\n\n13.76\n\n\n1.53\n\n\n2.70\n\n\n19.5\n\n\n132\n\n\n2.95\n\n\n2.74\n\n\n0.50\n\n\n1.35\n\n\n5.400000\n\n\n1.250\n\n\n3.00\n\n\n1235\n\n\nOne\n\n\n1\n\n\n13.51\n\n\n1.80\n\n\n2.65\n\n\n19.0\n\n\n110\n\n\n2.35\n\n\n2.53\n\n\n0.29\n\n\n1.54\n\n\n4.200000\n\n\n1.100\n\n\n2.87\n\n\n1095\n\n\nOne\n\n\n1\n\n\n13.48\n\n\n1.81\n\n\n2.41\n\n\n20.5\n\n\n100\n\n\n2.70\n\n\n2.98\n\n\n0.26\n\n\n1.86\n\n\n5.100000\n\n\n1.040\n\n\n3.47\n\n\n920\n\n\nOne\n\n\n1\n\n\n13.28\n\n\n1.64\n\n\n2.84\n\n\n15.5\n\n\n110\n\n\n2.60\n\n\n2.68\n\n\n0.34\n\n\n1.36\n\n\n4.600000\n\n\n1.090\n\n\n2.78\n\n\n880\n\n\nOne\n\n\n1\n\n\n13.05\n\n\n1.65\n\n\n2.55\n\n\n18.0\n\n\n98\n\n\n2.45\n\n\n2.43\n\n\n0.29\n\n\n1.44\n\n\n4.250000\n\n\n1.120\n\n\n2.51\n\n\n1105\n\n\nOne\n\n\n1\n\n\n13.07\n\n\n1.50\n\n\n2.10\n\n\n15.5\n\n\n98\n\n\n2.40\n\n\n2.64\n\n\n0.28\n\n\n1.37\n\n\n3.700000\n\n\n1.180\n\n\n2.69\n\n\n1020\n\n\nOne\n\n\n1\n\n\n14.22\n\n\n3.99\n\n\n2.51\n\n\n13.2\n\n\n128\n\n\n3.00\n\n\n3.04\n\n\n0.20\n\n\n2.08\n\n\n5.100000\n\n\n0.890\n\n\n3.53\n\n\n760\n\n\nOne\n\n\n1\n\n\n13.56\n\n\n1.71\n\n\n2.31\n\n\n16.2\n\n\n117\n\n\n3.15\n\n\n3.29\n\n\n0.34\n\n\n2.34\n\n\n6.130000\n\n\n0.950\n\n\n3.38\n\n\n795\n\n\nOne\n\n\n1\n\n\n13.41\n\n\n3.84\n\n\n2.12\n\n\n18.8\n\n\n90\n\n\n2.45\n\n\n2.68\n\n\n0.27\n\n\n1.48\n\n\n4.280000\n\n\n0.910\n\n\n3.00\n\n\n1035\n\n\nOne\n\n\n1\n\n\n13.88\n\n\n1.89\n\n\n2.59\n\n\n15.0\n\n\n101\n\n\n3.25\n\n\n3.56\n\n\n0.17\n\n\n1.70\n\n\n5.430000\n\n\n0.880\n\n\n3.56\n\n\n1095\n\n\nOne\n\n\n1\n\n\n13.24\n\n\n3.98\n\n\n2.29\n\n\n17.5\n\n\n103\n\n\n2.64\n\n\n2.63\n\n\n0.32\n\n\n1.66\n\n\n4.360000\n\n\n0.820\n\n\n3.00\n\n\n680\n\n\nOne\n\n\n1\n\n\n13.05\n\n\n1.77\n\n\n2.10\n\n\n17.0\n\n\n107\n\n\n3.00\n\n\n3.00\n\n\n0.28\n\n\n2.03\n\n\n5.040000\n\n\n0.880\n\n\n3.35\n\n\n885\n\n\nOne\n\n\n1\n\n\n14.21\n\n\n4.04\n\n\n2.44\n\n\n18.9\n\n\n111\n\n\n2.85\n\n\n2.65\n\n\n0.30\n\n\n1.25\n\n\n5.240000\n\n\n0.870\n\n\n3.33\n\n\n1080\n\n\nOne\n\n\n1\n\n\n14.38\n\n\n3.59\n\n\n2.28\n\n\n16.0\n\n\n102\n\n\n3.25\n\n\n3.17\n\n\n0.27\n\n\n2.19\n\n\n4.900000\n\n\n1.040\n\n\n3.44\n\n\n1065\n\n\nOne\n\n\n1\n\n\n13.90\n\n\n1.68\n\n\n2.12\n\n\n16.0\n\n\n101\n\n\n3.10\n\n\n3.39\n\n\n0.21\n\n\n2.14\n\n\n6.100000\n\n\n0.910\n\n\n3.33\n\n\n985\n\n\nOne\n\n\n1\n\n\n14.10\n\n\n2.02\n\n\n2.40\n\n\n18.8\n\n\n103\n\n\n2.75\n\n\n2.92\n\n\n0.32\n\n\n2.38\n\n\n6.200000\n\n\n1.070\n\n\n2.75\n\n\n1060\n\n\nOne\n\n\n1\n\n\n13.94\n\n\n1.73\n\n\n2.27\n\n\n17.4\n\n\n108\n\n\n2.88\n\n\n3.54\n\n\n0.32\n\n\n2.08\n\n\n8.900000\n\n\n1.120\n\n\n3.10\n\n\n1260\n\n\nOne\n\n\n1\n\n\n13.05\n\n\n1.73\n\n\n2.04\n\n\n12.4\n\n\n92\n\n\n2.72\n\n\n3.27\n\n\n0.17\n\n\n2.91\n\n\n7.200000\n\n\n1.120\n\n\n2.91\n\n\n1150\n\n\nOne\n\n\n1\n\n\n13.83\n\n\n1.65\n\n\n2.60\n\n\n17.2\n\n\n94\n\n\n2.45\n\n\n2.99\n\n\n0.22\n\n\n2.29\n\n\n5.600000\n\n\n1.240\n\n\n3.37\n\n\n1265\n\n\nOne\n\n\n1\n\n\n13.82\n\n\n1.75\n\n\n2.42\n\n\n14.0\n\n\n111\n\n\n3.88\n\n\n3.74\n\n\n0.32\n\n\n1.87\n\n\n7.050000\n\n\n1.010\n\n\n3.26\n\n\n1190\n\n\nOne\n\n\n1\n\n\n13.77\n\n\n1.90\n\n\n2.68\n\n\n17.1\n\n\n115\n\n\n3.00\n\n\n2.79\n\n\n0.39\n\n\n1.68\n\n\n6.300000\n\n\n1.130\n\n\n2.93\n\n\n1375\n\n\nOne\n\n\n1\n\n\n13.74\n\n\n1.67\n\n\n2.25\n\n\n16.4\n\n\n118\n\n\n2.60\n\n\n2.90\n\n\n0.21\n\n\n1.62\n\n\n5.850000\n\n\n0.920\n\n\n3.20\n\n\n1060\n\n\nOne\n\n\n1\n\n\n13.56\n\n\n1.73\n\n\n2.46\n\n\n20.5\n\n\n116\n\n\n2.96\n\n\n2.78\n\n\n0.20\n\n\n2.45\n\n\n6.250000\n\n\n0.980\n\n\n3.03\n\n\n1120\n\n\nOne\n\n\n1\n\n\n14.22\n\n\n1.70\n\n\n2.30\n\n\n16.3\n\n\n118\n\n\n3.20\n\n\n3.00\n\n\n0.26\n\n\n2.03\n\n\n6.380000\n\n\n0.940\n\n\n3.31\n\n\n970\n\n\nOne\n\n\n1\n\n\n13.29\n\n\n1.97\n\n\n2.68\n\n\n16.8\n\n\n102\n\n\n3.00\n\n\n3.23\n\n\n0.31\n\n\n1.66\n\n\n6.000000\n\n\n1.070\n\n\n2.84\n\n\n1270\n\n\nOne\n\n\n1\n\n\n13.72\n\n\n1.43\n\n\n2.50\n\n\n16.7\n\n\n108\n\n\n3.40\n\n\n3.67\n\n\n0.19\n\n\n2.04\n\n\n6.800000\n\n\n0.890\n\n\n2.87\n\n\n1285\n\n\nOne\n\n\n2\n\n\n12.37\n\n\n0.94\n\n\n1.36\n\n\n10.6\n\n\n88\n\n\n1.98\n\n\n0.57\n\n\n0.28\n\n\n0.42\n\n\n1.950000\n\n\n1.050\n\n\n1.82\n\n\n520\n\n\nTwo\n\n\n2\n\n\n12.33\n\n\n1.10\n\n\n2.28\n\n\n16.0\n\n\n101\n\n\n2.05\n\n\n1.09\n\n\n0.63\n\n\n0.41\n\n\n3.270000\n\n\n1.250\n\n\n1.67\n\n\n680\n\n\nTwo\n\n\n2\n\n\n12.64\n\n\n1.36\n\n\n2.02\n\n\n16.8\n\n\n100\n\n\n2.02\n\n\n1.41\n\n\n0.53\n\n\n0.62\n\n\n5.750000\n\n\n0.980\n\n\n1.59\n\n\n450\n\n\nTwo\n\n\n2\n\n\n13.67\n\n\n1.25\n\n\n1.92\n\n\n18.0\n\n\n94\n\n\n2.10\n\n\n1.79\n\n\n0.32\n\n\n0.73\n\n\n3.800000\n\n\n1.230\n\n\n2.46\n\n\n630\n\n\nTwo\n\n\n2\n\n\n12.37\n\n\n1.13\n\n\n2.16\n\n\n19.0\n\n\n87\n\n\n3.50\n\n\n3.10\n\n\n0.19\n\n\n1.87\n\n\n4.450000\n\n\n1.220\n\n\n2.87\n\n\n420\n\n\nTwo\n\n\n2\n\n\n12.17\n\n\n1.45\n\n\n2.53\n\n\n19.0\n\n\n104\n\n\n1.89\n\n\n1.75\n\n\n0.45\n\n\n1.03\n\n\n2.950000\n\n\n1.450\n\n\n2.23\n\n\n355\n\n\nTwo\n\n\n2\n\n\n12.37\n\n\n1.21\n\n\n2.56\n\n\n18.1\n\n\n98\n\n\n2.42\n\n\n2.65\n\n\n0.37\n\n\n2.08\n\n\n4.600000\n\n\n1.190\n\n\n2.30\n\n\n678\n\n\nTwo\n\n\n2\n\n\n13.11\n\n\n1.01\n\n\n1.70\n\n\n15.0\n\n\n78\n\n\n2.98\n\n\n3.18\n\n\n0.26\n\n\n2.28\n\n\n5.300000\n\n\n1.120\n\n\n3.18\n\n\n502\n\n\nTwo\n\n\n2\n\n\n12.37\n\n\n1.17\n\n\n1.92\n\n\n19.6\n\n\n78\n\n\n2.11\n\n\n2.00\n\n\n0.27\n\n\n1.04\n\n\n4.680000\n\n\n1.120\n\n\n3.48\n\n\n510\n\n\nTwo\n\n\n2\n\n\n13.34\n\n\n0.94\n\n\n2.36\n\n\n17.0\n\n\n110\n\n\n2.53\n\n\n1.30\n\n\n0.55\n\n\n0.42\n\n\n3.170000\n\n\n1.020\n\n\n1.93\n\n\n750\n\n\nTwo\n\n\n2\n\n\n12.21\n\n\n1.19\n\n\n1.75\n\n\n16.8\n\n\n151\n\n\n1.85\n\n\n1.28\n\n\n0.14\n\n\n2.50\n\n\n2.850000\n\n\n1.280\n\n\n3.07\n\n\n718\n\n\nTwo\n\n\n2\n\n\n12.29\n\n\n1.61\n\n\n2.21\n\n\n20.4\n\n\n103\n\n\n1.10\n\n\n1.02\n\n\n0.37\n\n\n1.46\n\n\n3.050000\n\n\n0.906\n\n\n1.82\n\n\n870\n\n\nTwo\n\n\n2\n\n\n13.86\n\n\n1.51\n\n\n2.67\n\n\n25.0\n\n\n86\n\n\n2.95\n\n\n2.86\n\n\n0.21\n\n\n1.87\n\n\n3.380000\n\n\n1.360\n\n\n3.16\n\n\n410\n\n\nTwo\n\n\n2\n\n\n13.49\n\n\n1.66\n\n\n2.24\n\n\n24.0\n\n\n87\n\n\n1.88\n\n\n1.84\n\n\n0.27\n\n\n1.03\n\n\n3.740000\n\n\n0.980\n\n\n2.78\n\n\n472\n\n\nTwo\n\n\n2\n\n\n12.99\n\n\n1.67\n\n\n2.60\n\n\n30.0\n\n\n139\n\n\n3.30\n\n\n2.89\n\n\n0.21\n\n\n1.96\n\n\n3.350000\n\n\n1.310\n\n\n3.50\n\n\n985\n\n\nTwo\n\n\n2\n\n\n11.96\n\n\n1.09\n\n\n2.30\n\n\n21.0\n\n\n101\n\n\n3.38\n\n\n2.14\n\n\n0.13\n\n\n1.65\n\n\n3.210000\n\n\n0.990\n\n\n3.13\n\n\n886\n\n\nTwo\n\n\n2\n\n\n11.66\n\n\n1.88\n\n\n1.92\n\n\n16.0\n\n\n97\n\n\n1.61\n\n\n1.57\n\n\n0.34\n\n\n1.15\n\n\n3.800000\n\n\n1.230\n\n\n2.14\n\n\n428\n\n\nTwo\n\n\n2\n\n\n13.03\n\n\n0.90\n\n\n1.71\n\n\n16.0\n\n\n86\n\n\n1.95\n\n\n2.03\n\n\n0.24\n\n\n1.46\n\n\n4.600000\n\n\n1.190\n\n\n2.48\n\n\n392\n\n\nTwo\n\n\n2\n\n\n11.84\n\n\n2.89\n\n\n2.23\n\n\n18.0\n\n\n112\n\n\n1.72\n\n\n1.32\n\n\n0.43\n\n\n0.95\n\n\n2.650000\n\n\n0.960\n\n\n2.52\n\n\n500\n\n\nTwo\n\n\n2\n\n\n12.33\n\n\n0.99\n\n\n1.95\n\n\n14.8\n\n\n136\n\n\n1.90\n\n\n1.85\n\n\n0.35\n\n\n2.76\n\n\n3.400000\n\n\n1.060\n\n\n2.31\n\n\n750\n\n\nTwo\n\n\n2\n\n\n12.70\n\n\n3.87\n\n\n2.40\n\n\n23.0\n\n\n101\n\n\n2.83\n\n\n2.55\n\n\n0.43\n\n\n1.95\n\n\n2.570000\n\n\n1.190\n\n\n3.13\n\n\n463\n\n\nTwo\n\n\n2\n\n\n12.00\n\n\n0.92\n\n\n2.00\n\n\n19.0\n\n\n86\n\n\n2.42\n\n\n2.26\n\n\n0.30\n\n\n1.43\n\n\n2.500000\n\n\n1.380\n\n\n3.12\n\n\n278\n\n\nTwo\n\n\n2\n\n\n12.72\n\n\n1.81\n\n\n2.20\n\n\n18.8\n\n\n86\n\n\n2.20\n\n\n2.53\n\n\n0.26\n\n\n1.77\n\n\n3.900000\n\n\n1.160\n\n\n3.14\n\n\n714\n\n\nTwo\n\n\n2\n\n\n12.08\n\n\n1.13\n\n\n2.51\n\n\n24.0\n\n\n78\n\n\n2.00\n\n\n1.58\n\n\n0.40\n\n\n1.40\n\n\n2.200000\n\n\n1.310\n\n\n2.72\n\n\n630\n\n\nTwo\n\n\n2\n\n\n13.05\n\n\n3.86\n\n\n2.32\n\n\n22.5\n\n\n85\n\n\n1.65\n\n\n1.59\n\n\n0.61\n\n\n1.62\n\n\n4.800000\n\n\n0.840\n\n\n2.01\n\n\n515\n\n\nTwo\n\n\n2\n\n\n11.84\n\n\n0.89\n\n\n2.58\n\n\n18.0\n\n\n94\n\n\n2.20\n\n\n2.21\n\n\n0.22\n\n\n2.35\n\n\n3.050000\n\n\n0.790\n\n\n3.08\n\n\n520\n\n\nTwo\n\n\n2\n\n\n12.67\n\n\n0.98\n\n\n2.24\n\n\n18.0\n\n\n99\n\n\n2.20\n\n\n1.94\n\n\n0.30\n\n\n1.46\n\n\n2.620000\n\n\n1.230\n\n\n3.16\n\n\n450\n\n\nTwo\n\n\n2\n\n\n12.16\n\n\n1.61\n\n\n2.31\n\n\n22.8\n\n\n90\n\n\n1.78\n\n\n1.69\n\n\n0.43\n\n\n1.56\n\n\n2.450000\n\n\n1.330\n\n\n2.26\n\n\n495\n\n\nTwo\n\n\n2\n\n\n11.65\n\n\n1.67\n\n\n2.62\n\n\n26.0\n\n\n88\n\n\n1.92\n\n\n1.61\n\n\n0.40\n\n\n1.34\n\n\n2.600000\n\n\n1.360\n\n\n3.21\n\n\n562\n\n\nTwo\n\n\n2\n\n\n11.64\n\n\n2.06\n\n\n2.46\n\n\n21.6\n\n\n84\n\n\n1.95\n\n\n1.69\n\n\n0.48\n\n\n1.35\n\n\n2.800000\n\n\n1.000\n\n\n2.75\n\n\n680\n\n\nTwo\n\n\n2\n\n\n12.08\n\n\n1.33\n\n\n2.30\n\n\n23.6\n\n\n70\n\n\n2.20\n\n\n1.59\n\n\n0.42\n\n\n1.38\n\n\n1.740000\n\n\n1.070\n\n\n3.21\n\n\n625\n\n\nTwo\n\n\n2\n\n\n12.08\n\n\n1.83\n\n\n2.32\n\n\n18.5\n\n\n81\n\n\n1.60\n\n\n1.50\n\n\n0.52\n\n\n1.64\n\n\n2.400000\n\n\n1.080\n\n\n2.27\n\n\n480\n\n\nTwo\n\n\n2\n\n\n12.00\n\n\n1.51\n\n\n2.42\n\n\n22.0\n\n\n86\n\n\n1.45\n\n\n1.25\n\n\n0.50\n\n\n1.63\n\n\n3.600000\n\n\n1.050\n\n\n2.65\n\n\n450\n\n\nTwo\n\n\n2\n\n\n12.69\n\n\n1.53\n\n\n2.26\n\n\n20.7\n\n\n80\n\n\n1.38\n\n\n1.46\n\n\n0.58\n\n\n1.62\n\n\n3.050000\n\n\n0.960\n\n\n2.06\n\n\n495\n\n\nTwo\n\n\n2\n\n\n12.29\n\n\n2.83\n\n\n2.22\n\n\n18.0\n\n\n88\n\n\n2.45\n\n\n2.25\n\n\n0.25\n\n\n1.99\n\n\n2.150000\n\n\n1.150\n\n\n3.30\n\n\n290\n\n\nTwo\n\n\n2\n\n\n11.62\n\n\n1.99\n\n\n2.28\n\n\n18.0\n\n\n98\n\n\n3.02\n\n\n2.26\n\n\n0.17\n\n\n1.35\n\n\n3.250000\n\n\n1.160\n\n\n2.96\n\n\n345\n\n\nTwo\n\n\n2\n\n\n12.47\n\n\n1.52\n\n\n2.20\n\n\n19.0\n\n\n162\n\n\n2.50\n\n\n2.27\n\n\n0.32\n\n\n3.28\n\n\n2.600000\n\n\n1.160\n\n\n2.63\n\n\n937\n\n\nTwo\n\n\n2\n\n\n11.81\n\n\n2.12\n\n\n2.74\n\n\n21.5\n\n\n134\n\n\n1.60\n\n\n0.99\n\n\n0.14\n\n\n1.56\n\n\n2.500000\n\n\n0.950\n\n\n2.26\n\n\n625\n\n\nTwo\n\n\n2\n\n\n12.29\n\n\n1.41\n\n\n1.98\n\n\n16.0\n\n\n85\n\n\n2.55\n\n\n2.50\n\n\n0.29\n\n\n1.77\n\n\n2.900000\n\n\n1.230\n\n\n2.74\n\n\n428\n\n\nTwo\n\n\n2\n\n\n12.37\n\n\n1.07\n\n\n2.10\n\n\n18.5\n\n\n88\n\n\n3.52\n\n\n3.75\n\n\n0.24\n\n\n1.95\n\n\n4.500000\n\n\n1.040\n\n\n2.77\n\n\n660\n\n\nTwo\n\n\n2\n\n\n12.29\n\n\n3.17\n\n\n2.21\n\n\n18.0\n\n\n88\n\n\n2.85\n\n\n2.99\n\n\n0.45\n\n\n2.81\n\n\n2.300000\n\n\n1.420\n\n\n2.83\n\n\n406\n\n\nTwo\n\n\n2\n\n\n12.08\n\n\n2.08\n\n\n1.70\n\n\n17.5\n\n\n97\n\n\n2.23\n\n\n2.17\n\n\n0.26\n\n\n1.40\n\n\n3.300000\n\n\n1.270\n\n\n2.96\n\n\n710\n\n\nTwo\n\n\n2\n\n\n12.60\n\n\n1.34\n\n\n1.90\n\n\n18.5\n\n\n88\n\n\n1.45\n\n\n1.36\n\n\n0.29\n\n\n1.35\n\n\n2.450000\n\n\n1.040\n\n\n2.77\n\n\n562\n\n\nTwo\n\n\n2\n\n\n12.34\n\n\n2.45\n\n\n2.46\n\n\n21.0\n\n\n98\n\n\n2.56\n\n\n2.11\n\n\n0.34\n\n\n1.31\n\n\n2.800000\n\n\n0.800\n\n\n3.38\n\n\n438\n\n\nTwo\n\n\n2\n\n\n11.82\n\n\n1.72\n\n\n1.88\n\n\n19.5\n\n\n86\n\n\n2.50\n\n\n1.64\n\n\n0.37\n\n\n1.42\n\n\n2.060000\n\n\n0.940\n\n\n2.44\n\n\n415\n\n\nTwo\n\n\n2\n\n\n12.51\n\n\n1.73\n\n\n1.98\n\n\n20.5\n\n\n85\n\n\n2.20\n\n\n1.92\n\n\n0.32\n\n\n1.48\n\n\n2.940000\n\n\n1.040\n\n\n3.57\n\n\n672\n\n\nTwo\n\n\n2\n\n\n12.42\n\n\n2.55\n\n\n2.27\n\n\n22.0\n\n\n90\n\n\n1.68\n\n\n1.84\n\n\n0.66\n\n\n1.42\n\n\n2.700000\n\n\n0.860\n\n\n3.30\n\n\n315\n\n\nTwo\n\n\n2\n\n\n12.25\n\n\n1.73\n\n\n2.12\n\n\n19.0\n\n\n80\n\n\n1.65\n\n\n2.03\n\n\n0.37\n\n\n1.63\n\n\n3.400000\n\n\n1.000\n\n\n3.17\n\n\n510\n\n\nTwo\n\n\n2\n\n\n12.72\n\n\n1.75\n\n\n2.28\n\n\n22.5\n\n\n84\n\n\n1.38\n\n\n1.76\n\n\n0.48\n\n\n1.63\n\n\n3.300000\n\n\n0.880\n\n\n2.42\n\n\n488\n\n\nTwo\n\n\n2\n\n\n12.22\n\n\n1.29\n\n\n1.94\n\n\n19.0\n\n\n92\n\n\n2.36\n\n\n2.04\n\n\n0.39\n\n\n2.08\n\n\n2.700000\n\n\n0.860\n\n\n3.02\n\n\n312\n\n\nTwo\n\n\n2\n\n\n11.61\n\n\n1.35\n\n\n2.70\n\n\n20.0\n\n\n94\n\n\n2.74\n\n\n2.92\n\n\n0.29\n\n\n2.49\n\n\n2.650000\n\n\n0.960\n\n\n3.26\n\n\n680\n\n\nTwo\n\n\n2\n\n\n11.46\n\n\n3.74\n\n\n1.82\n\n\n19.5\n\n\n107\n\n\n3.18\n\n\n2.58\n\n\n0.24\n\n\n3.58\n\n\n2.900000\n\n\n0.750\n\n\n2.81\n\n\n562\n\n\nTwo\n\n\n2\n\n\n12.52\n\n\n2.43\n\n\n2.17\n\n\n21.0\n\n\n88\n\n\n2.55\n\n\n2.27\n\n\n0.26\n\n\n1.22\n\n\n2.000000\n\n\n0.900\n\n\n2.78\n\n\n325\n\n\nTwo\n\n\n2\n\n\n11.76\n\n\n2.68\n\n\n2.92\n\n\n20.0\n\n\n103\n\n\n1.75\n\n\n2.03\n\n\n0.60\n\n\n1.05\n\n\n3.800000\n\n\n1.230\n\n\n2.50\n\n\n607\n\n\nTwo\n\n\n2\n\n\n11.41\n\n\n0.74\n\n\n2.50\n\n\n21.0\n\n\n88\n\n\n2.48\n\n\n2.01\n\n\n0.42\n\n\n1.44\n\n\n3.080000\n\n\n1.100\n\n\n2.31\n\n\n434\n\n\nTwo\n\n\n2\n\n\n12.08\n\n\n1.39\n\n\n2.50\n\n\n22.5\n\n\n84\n\n\n2.56\n\n\n2.29\n\n\n0.43\n\n\n1.04\n\n\n2.900000\n\n\n0.930\n\n\n3.19\n\n\n385\n\n\nTwo\n\n\n2\n\n\n11.03\n\n\n1.51\n\n\n2.20\n\n\n21.5\n\n\n85\n\n\n2.46\n\n\n2.17\n\n\n0.52\n\n\n2.01\n\n\n1.900000\n\n\n1.710\n\n\n2.87\n\n\n407\n\n\nTwo\n\n\n2\n\n\n11.82\n\n\n1.47\n\n\n1.99\n\n\n20.8\n\n\n86\n\n\n1.98\n\n\n1.60\n\n\n0.30\n\n\n1.53\n\n\n1.950000\n\n\n0.950\n\n\n3.33\n\n\n495\n\n\nTwo\n\n\n2\n\n\n12.42\n\n\n1.61\n\n\n2.19\n\n\n22.5\n\n\n108\n\n\n2.00\n\n\n2.09\n\n\n0.34\n\n\n1.61\n\n\n2.060000\n\n\n1.060\n\n\n2.96\n\n\n345\n\n\nTwo\n\n\n2\n\n\n12.77\n\n\n3.43\n\n\n1.98\n\n\n16.0\n\n\n80\n\n\n1.63\n\n\n1.25\n\n\n0.43\n\n\n0.83\n\n\n3.400000\n\n\n0.700\n\n\n2.12\n\n\n372\n\n\nTwo\n\n\n2\n\n\n12.00\n\n\n3.43\n\n\n2.00\n\n\n19.0\n\n\n87\n\n\n2.00\n\n\n1.64\n\n\n0.37\n\n\n1.87\n\n\n1.280000\n\n\n0.930\n\n\n3.05\n\n\n564\n\n\nTwo\n\n\n2\n\n\n11.45\n\n\n2.40\n\n\n2.42\n\n\n20.0\n\n\n96\n\n\n2.90\n\n\n2.79\n\n\n0.32\n\n\n1.83\n\n\n3.250000\n\n\n0.800\n\n\n3.39\n\n\n625\n\n\nTwo\n\n\n2\n\n\n11.56\n\n\n2.05\n\n\n3.23\n\n\n28.5\n\n\n119\n\n\n3.18\n\n\n5.08\n\n\n0.47\n\n\n1.87\n\n\n6.000000\n\n\n0.930\n\n\n3.69\n\n\n465\n\n\nTwo\n\n\n2\n\n\n12.42\n\n\n4.43\n\n\n2.73\n\n\n26.5\n\n\n102\n\n\n2.20\n\n\n2.13\n\n\n0.43\n\n\n1.71\n\n\n2.080000\n\n\n0.920\n\n\n3.12\n\n\n365\n\n\nTwo\n\n\n2\n\n\n13.05\n\n\n5.80\n\n\n2.13\n\n\n21.5\n\n\n86\n\n\n2.62\n\n\n2.65\n\n\n0.30\n\n\n2.01\n\n\n2.600000\n\n\n0.730\n\n\n3.10\n\n\n380\n\n\nTwo\n\n\n2\n\n\n11.87\n\n\n4.31\n\n\n2.39\n\n\n21.0\n\n\n82\n\n\n2.86\n\n\n3.03\n\n\n0.21\n\n\n2.91\n\n\n2.800000\n\n\n0.750\n\n\n3.64\n\n\n380\n\n\nTwo\n\n\n2\n\n\n12.07\n\n\n2.16\n\n\n2.17\n\n\n21.0\n\n\n85\n\n\n2.60\n\n\n2.65\n\n\n0.37\n\n\n1.35\n\n\n2.760000\n\n\n0.860\n\n\n3.28\n\n\n378\n\n\nTwo\n\n\n2\n\n\n12.43\n\n\n1.53\n\n\n2.29\n\n\n21.5\n\n\n86\n\n\n2.74\n\n\n3.15\n\n\n0.39\n\n\n1.77\n\n\n3.940000\n\n\n0.690\n\n\n2.84\n\n\n352\n\n\nTwo\n\n\n2\n\n\n11.79\n\n\n2.13\n\n\n2.78\n\n\n28.5\n\n\n92\n\n\n2.13\n\n\n2.24\n\n\n0.58\n\n\n1.76\n\n\n3.000000\n\n\n0.970\n\n\n2.44\n\n\n466\n\n\nTwo\n\n\n2\n\n\n12.37\n\n\n1.63\n\n\n2.30\n\n\n24.5\n\n\n88\n\n\n2.22\n\n\n2.45\n\n\n0.40\n\n\n1.90\n\n\n2.120000\n\n\n0.890\n\n\n2.78\n\n\n342\n\n\nTwo\n\n\n2\n\n\n12.04\n\n\n4.30\n\n\n2.38\n\n\n22.0\n\n\n80\n\n\n2.10\n\n\n1.75\n\n\n0.42\n\n\n1.35\n\n\n2.600000\n\n\n0.790\n\n\n2.57\n\n\n580\n\n\nTwo\n\n\n3\n\n\n12.86\n\n\n1.35\n\n\n2.32\n\n\n18.0\n\n\n122\n\n\n1.51\n\n\n1.25\n\n\n0.21\n\n\n0.94\n\n\n4.100000\n\n\n0.760\n\n\n1.29\n\n\n630\n\n\nThree\n\n\n3\n\n\n12.88\n\n\n2.99\n\n\n2.40\n\n\n20.0\n\n\n104\n\n\n1.30\n\n\n1.22\n\n\n0.24\n\n\n0.83\n\n\n5.400000\n\n\n0.740\n\n\n1.42\n\n\n530\n\n\nThree\n\n\n3\n\n\n12.81\n\n\n2.31\n\n\n2.40\n\n\n24.0\n\n\n98\n\n\n1.15\n\n\n1.09\n\n\n0.27\n\n\n0.83\n\n\n5.700000\n\n\n0.660\n\n\n1.36\n\n\n560\n\n\nThree\n\n\n3\n\n\n12.70\n\n\n3.55\n\n\n2.36\n\n\n21.5\n\n\n106\n\n\n1.70\n\n\n1.20\n\n\n0.17\n\n\n0.84\n\n\n5.000000\n\n\n0.780\n\n\n1.29\n\n\n600\n\n\nThree\n\n\n3\n\n\n12.51\n\n\n1.24\n\n\n2.25\n\n\n17.5\n\n\n85\n\n\n2.00\n\n\n0.58\n\n\n0.60\n\n\n1.25\n\n\n5.450000\n\n\n0.750\n\n\n1.51\n\n\n650\n\n\nThree\n\n\n3\n\n\n12.60\n\n\n2.46\n\n\n2.20\n\n\n18.5\n\n\n94\n\n\n1.62\n\n\n0.66\n\n\n0.63\n\n\n0.94\n\n\n7.100000\n\n\n0.730\n\n\n1.58\n\n\n695\n\n\nThree\n\n\n3\n\n\n12.25\n\n\n4.72\n\n\n2.54\n\n\n21.0\n\n\n89\n\n\n1.38\n\n\n0.47\n\n\n0.53\n\n\n0.80\n\n\n3.850000\n\n\n0.750\n\n\n1.27\n\n\n720\n\n\nThree\n\n\n3\n\n\n12.53\n\n\n5.51\n\n\n2.64\n\n\n25.0\n\n\n96\n\n\n1.79\n\n\n0.60\n\n\n0.63\n\n\n1.10\n\n\n5.000000\n\n\n0.820\n\n\n1.69\n\n\n515\n\n\nThree\n\n\n3\n\n\n13.49\n\n\n3.59\n\n\n2.19\n\n\n19.5\n\n\n88\n\n\n1.62\n\n\n0.48\n\n\n0.58\n\n\n0.88\n\n\n5.700000\n\n\n0.810\n\n\n1.82\n\n\n580\n\n\nThree\n\n\n3\n\n\n12.84\n\n\n2.96\n\n\n2.61\n\n\n24.0\n\n\n101\n\n\n2.32\n\n\n0.60\n\n\n0.53\n\n\n0.81\n\n\n4.920000\n\n\n0.890\n\n\n2.15\n\n\n590\n\n\nThree\n\n\n3\n\n\n12.93\n\n\n2.81\n\n\n2.70\n\n\n21.0\n\n\n96\n\n\n1.54\n\n\n0.50\n\n\n0.53\n\n\n0.75\n\n\n4.600000\n\n\n0.770\n\n\n2.31\n\n\n600\n\n\nThree\n\n\n3\n\n\n13.36\n\n\n2.56\n\n\n2.35\n\n\n20.0\n\n\n89\n\n\n1.40\n\n\n0.50\n\n\n0.37\n\n\n0.64\n\n\n5.600000\n\n\n0.700\n\n\n2.47\n\n\n780\n\n\nThree\n\n\n3\n\n\n13.52\n\n\n3.17\n\n\n2.72\n\n\n23.5\n\n\n97\n\n\n1.55\n\n\n0.52\n\n\n0.50\n\n\n0.55\n\n\n4.350000\n\n\n0.890\n\n\n2.06\n\n\n520\n\n\nThree\n\n\n3\n\n\n13.62\n\n\n4.95\n\n\n2.35\n\n\n20.0\n\n\n92\n\n\n2.00\n\n\n0.80\n\n\n0.47\n\n\n1.02\n\n\n4.400000\n\n\n0.910\n\n\n2.05\n\n\n550\n\n\nThree\n\n\n3\n\n\n12.25\n\n\n3.88\n\n\n2.20\n\n\n18.5\n\n\n112\n\n\n1.38\n\n\n0.78\n\n\n0.29\n\n\n1.14\n\n\n8.210000\n\n\n0.650\n\n\n2.00\n\n\n855\n\n\nThree\n\n\n3\n\n\n13.16\n\n\n3.57\n\n\n2.15\n\n\n21.0\n\n\n102\n\n\n1.50\n\n\n0.55\n\n\n0.43\n\n\n1.30\n\n\n4.000000\n\n\n0.600\n\n\n1.68\n\n\n830\n\n\nThree\n\n\n3\n\n\n13.88\n\n\n5.04\n\n\n2.23\n\n\n20.0\n\n\n80\n\n\n0.98\n\n\n0.34\n\n\n0.40\n\n\n0.68\n\n\n4.900000\n\n\n0.580\n\n\n1.33\n\n\n415\n\n\nThree\n\n\n3\n\n\n12.87\n\n\n4.61\n\n\n2.48\n\n\n21.5\n\n\n86\n\n\n1.70\n\n\n0.65\n\n\n0.47\n\n\n0.86\n\n\n7.650000\n\n\n0.540\n\n\n1.86\n\n\n625\n\n\nThree\n\n\n3\n\n\n13.32\n\n\n3.24\n\n\n2.38\n\n\n21.5\n\n\n92\n\n\n1.93\n\n\n0.76\n\n\n0.45\n\n\n1.25\n\n\n8.420000\n\n\n0.550\n\n\n1.62\n\n\n650\n\n\nThree\n\n\n3\n\n\n13.08\n\n\n3.90\n\n\n2.36\n\n\n21.5\n\n\n113\n\n\n1.41\n\n\n1.39\n\n\n0.34\n\n\n1.14\n\n\n9.400000\n\n\n0.570\n\n\n1.33\n\n\n550\n\n\nThree\n\n\n3\n\n\n13.50\n\n\n3.12\n\n\n2.62\n\n\n24.0\n\n\n123\n\n\n1.40\n\n\n1.57\n\n\n0.22\n\n\n1.25\n\n\n8.600000\n\n\n0.590\n\n\n1.30\n\n\n500\n\n\nThree\n\n\n3\n\n\n12.79\n\n\n2.67\n\n\n2.48\n\n\n22.0\n\n\n112\n\n\n1.48\n\n\n1.36\n\n\n0.24\n\n\n1.26\n\n\n10.800000\n\n\n0.480\n\n\n1.47\n\n\n480\n\n\nThree\n\n\n3\n\n\n13.11\n\n\n1.90\n\n\n2.75\n\n\n25.5\n\n\n116\n\n\n2.20\n\n\n1.28\n\n\n0.26\n\n\n1.56\n\n\n7.100000\n\n\n0.610\n\n\n1.33\n\n\n425\n\n\nThree\n\n\n3\n\n\n13.23\n\n\n3.30\n\n\n2.28\n\n\n18.5\n\n\n98\n\n\n1.80\n\n\n0.83\n\n\n0.61\n\n\n1.87\n\n\n10.520000\n\n\n0.560\n\n\n1.51\n\n\n675\n\n\nThree\n\n\n3\n\n\n12.58\n\n\n1.29\n\n\n2.10\n\n\n20.0\n\n\n103\n\n\n1.48\n\n\n0.58\n\n\n0.53\n\n\n1.40\n\n\n7.600000\n\n\n0.580\n\n\n1.55\n\n\n640\n\n\nThree\n\n\n3\n\n\n13.17\n\n\n5.19\n\n\n2.32\n\n\n22.0\n\n\n93\n\n\n1.74\n\n\n0.63\n\n\n0.61\n\n\n1.55\n\n\n7.900000\n\n\n0.600\n\n\n1.48\n\n\n725\n\n\nThree\n\n\n3\n\n\n13.84\n\n\n4.12\n\n\n2.38\n\n\n19.5\n\n\n89\n\n\n1.80\n\n\n0.83\n\n\n0.48\n\n\n1.56\n\n\n9.010000\n\n\n0.570\n\n\n1.64\n\n\n480\n\n\nThree\n\n\n3\n\n\n12.45\n\n\n3.03\n\n\n2.64\n\n\n27.0\n\n\n97\n\n\n1.90\n\n\n0.58\n\n\n0.63\n\n\n1.14\n\n\n7.500000\n\n\n0.670\n\n\n1.73\n\n\n880\n\n\nThree\n\n\n3\n\n\n14.34\n\n\n1.68\n\n\n2.70\n\n\n25.0\n\n\n98\n\n\n2.80\n\n\n1.31\n\n\n0.53\n\n\n2.70\n\n\n13.000000\n\n\n0.570\n\n\n1.96\n\n\n660\n\n\nThree\n\n\n3\n\n\n13.48\n\n\n1.67\n\n\n2.64\n\n\n22.5\n\n\n89\n\n\n2.60\n\n\n1.10\n\n\n0.52\n\n\n2.29\n\n\n11.750000\n\n\n0.570\n\n\n1.78\n\n\n620\n\n\nThree\n\n\n3\n\n\n12.36\n\n\n3.83\n\n\n2.38\n\n\n21.0\n\n\n88\n\n\n2.30\n\n\n0.92\n\n\n0.50\n\n\n1.04\n\n\n7.650000\n\n\n0.560\n\n\n1.58\n\n\n520\n\n\nThree\n\n\n3\n\n\n13.69\n\n\n3.26\n\n\n2.54\n\n\n20.0\n\n\n107\n\n\n1.83\n\n\n0.56\n\n\n0.50\n\n\n0.80\n\n\n5.880000\n\n\n0.960\n\n\n1.82\n\n\n680\n\n\nThree\n\n\n3\n\n\n12.85\n\n\n3.27\n\n\n2.58\n\n\n22.0\n\n\n106\n\n\n1.65\n\n\n0.60\n\n\n0.60\n\n\n0.96\n\n\n5.580000\n\n\n0.870\n\n\n2.11\n\n\n570\n\n\nThree\n\n\n3\n\n\n12.96\n\n\n3.45\n\n\n2.35\n\n\n18.5\n\n\n106\n\n\n1.39\n\n\n0.70\n\n\n0.40\n\n\n0.94\n\n\n5.280000\n\n\n0.680\n\n\n1.75\n\n\n675\n\n\nThree\n\n\n3\n\n\n13.78\n\n\n2.76\n\n\n2.30\n\n\n22.0\n\n\n90\n\n\n1.35\n\n\n0.68\n\n\n0.41\n\n\n1.03\n\n\n9.580000\n\n\n0.700\n\n\n1.68\n\n\n615\n\n\nThree\n\n\n3\n\n\n13.73\n\n\n4.36\n\n\n2.26\n\n\n22.5\n\n\n88\n\n\n1.28\n\n\n0.47\n\n\n0.52\n\n\n1.15\n\n\n6.620000\n\n\n0.780\n\n\n1.75\n\n\n520\n\n\nThree\n\n\n3\n\n\n13.45\n\n\n3.70\n\n\n2.60\n\n\n23.0\n\n\n111\n\n\n1.70\n\n\n0.92\n\n\n0.43\n\n\n1.46\n\n\n10.680000\n\n\n0.850\n\n\n1.56\n\n\n695\n\n\nThree\n\n\n3\n\n\n12.82\n\n\n3.37\n\n\n2.30\n\n\n19.5\n\n\n88\n\n\n1.48\n\n\n0.66\n\n\n0.40\n\n\n0.97\n\n\n10.260000\n\n\n0.720\n\n\n1.75\n\n\n685\n\n\nThree\n\n\n3\n\n\n13.58\n\n\n2.58\n\n\n2.69\n\n\n24.5\n\n\n105\n\n\n1.55\n\n\n0.84\n\n\n0.39\n\n\n1.54\n\n\n8.660000\n\n\n0.740\n\n\n1.80\n\n\n750\n\n\nThree\n\n\n3\n\n\n13.40\n\n\n4.60\n\n\n2.86\n\n\n25.0\n\n\n112\n\n\n1.98\n\n\n0.96\n\n\n0.27\n\n\n1.11\n\n\n8.500000\n\n\n0.670\n\n\n1.92\n\n\n630\n\n\nThree\n\n\n3\n\n\n12.20\n\n\n3.03\n\n\n2.32\n\n\n19.0\n\n\n96\n\n\n1.25\n\n\n0.49\n\n\n0.40\n\n\n0.73\n\n\n5.500000\n\n\n0.660\n\n\n1.83\n\n\n510\n\n\nThree\n\n\n3\n\n\n12.77\n\n\n2.39\n\n\n2.28\n\n\n19.5\n\n\n86\n\n\n1.39\n\n\n0.51\n\n\n0.48\n\n\n0.64\n\n\n9.899999\n\n\n0.570\n\n\n1.63\n\n\n470\n\n\nThree\n\n\n3\n\n\n14.16\n\n\n2.51\n\n\n2.48\n\n\n20.0\n\n\n91\n\n\n1.68\n\n\n0.70\n\n\n0.44\n\n\n1.24\n\n\n9.700000\n\n\n0.620\n\n\n1.71\n\n\n660\n\n\nThree\n\n\n3\n\n\n13.71\n\n\n5.65\n\n\n2.45\n\n\n20.5\n\n\n95\n\n\n1.68\n\n\n0.61\n\n\n0.52\n\n\n1.06\n\n\n7.700000\n\n\n0.640\n\n\n1.74\n\n\n740\n\n\nThree\n\n\n3\n\n\n13.40\n\n\n3.91\n\n\n2.48\n\n\n23.0\n\n\n102\n\n\n1.80\n\n\n0.75\n\n\n0.43\n\n\n1.41\n\n\n7.300000\n\n\n0.700\n\n\n1.56\n\n\n750\n\n\nThree\n\n\n3\n\n\n13.27\n\n\n4.28\n\n\n2.26\n\n\n20.0\n\n\n120\n\n\n1.59\n\n\n0.69\n\n\n0.43\n\n\n1.35\n\n\n10.200000\n\n\n0.590\n\n\n1.56\n\n\n835\n\n\nThree\n\n\n3\n\n\n13.17\n\n\n2.59\n\n\n2.37\n\n\n20.0\n\n\n120\n\n\n1.65\n\n\n0.68\n\n\n0.53\n\n\n1.46\n\n\n9.300000\n\n\n0.600\n\n\n1.62\n\n\n840\n\n\nThree\n\n\n3\n\n\n14.13\n\n\n4.10\n\n\n2.74\n\n\n24.5\n\n\n96\n\n\n2.05\n\n\n0.76\n\n\n0.56\n\n\n1.35\n\n\n9.200000\n\n\n0.610\n\n\n1.60\n\n\n560\n\n\nThree\n\n\n\n\n\n# Overall relationships among variables\nGGally::ggpairs(WineDate2, aes(color = Class, alpha = 0.5))\n\n\n\n# This one seem to separate wine classes well\nggplot(data=WineDate2,mapping = aes(x=Proline,y=Color.intensity,color=Class))+\n  geom_point(alpha=0.5)\n\n\n\n\nFrom this plot, we can see that variables Proline and Color intensity seem to be good classifier or estimator of wine class. Next, we can use boxplot to verify this assumption.\n\n\nggplot(WineDate2, aes(x = Class, y = Proline, color= Class))+\n  geom_boxplot()+ \n  ggtitle(\"Class vs. Proline\")\n\n\n\nggplot(WineDate2, aes(x = Class, y = Color.intensity, color= Class ))+\n  geom_boxplot()+ \n  ggtitle(\"Class vs. Color Intensity\")\n\n\n\n\nBoth boxplots indicates that wine classes could be determined based on the mean of variables since they are different.\nProcess the wine data\n\n\ntrainIndex <- createDataPartition(WineDate2$class, p = .6, list = FALSE, times = 1)\n\nSVMTrain <- WineDate2[ trainIndex,]\nSVMTest  <- WineDate2[-trainIndex,]\n\nWine_SVM <- train(\n  form = as.factor(class)~ .,\n  data = SVMTrain,\n  trControl = trainControl(method = \"cv\", number = 10,\n                           classProbs =  TRUE),\n  method = \"svmLinear\",\n  preProcess = c(\"center\", \"scale\"),\n  tuneLength = 10)\nWine_SVM\n\n\nSupport Vector Machines with Linear Kernel \n\n107 samples\n 14 predictor\n  3 classes: 'One', 'Three', 'Two' \n\nPre-processing: centered (15), scaled (15) \nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 96, 97, 96, 96, 98, 96, ... \nResampling results:\n\n  Accuracy  Kappa\n  1         1    \n\nTuning parameter 'C' was held constant at a value of 1\n\nsummary(Wine_SVM)\n\n\nLength  Class   Mode \n     1   ksvm     S4 \n\nsvm_Pred<-predict(Wine_SVM,SVMTest,type=\"prob\")\n\nsvmtestpred<-cbind(svm_Pred,SVMTest)\n\nsvmtestpred<-svmtestpred%>%\n  mutate(prediction=if_else(One>Two & One>Three,\"One\",\n                            if_else(Two>One & Two>Three, \"Two\",\n                                    if_else(Three>One & Three>Two,\"Three\", \"PROBLEM\"))))\n\ntable(svmtestpred$prediction)\n\n\n\n  One Three   Two \n   23    19    28 \n\nconfusionMatrix(factor(svmtestpred$prediction),factor(svmtestpred$class))\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction One Three Two\n     One    23     0   0\n     Three   0    19   0\n     Two     0     0  28\n\nOverall Statistics\n                                     \n               Accuracy : 1          \n                 95% CI : (0.9487, 1)\n    No Information Rate : 0.4        \n    P-Value [Acc > NIR] : < 2.2e-16  \n                                     \n                  Kappa : 1          \n                                     \n Mcnemar's Test P-Value : NA         \n\nStatistics by Class:\n\n                     Class: One Class: Three Class: Two\nSensitivity              1.0000       1.0000        1.0\nSpecificity              1.0000       1.0000        1.0\nPos Pred Value           1.0000       1.0000        1.0\nNeg Pred Value           1.0000       1.0000        1.0\nPrevalence               0.3286       0.2714        0.4\nDetection Rate           0.3286       0.2714        0.4\nDetection Prevalence     0.3286       0.2714        0.4\nBalanced Accuracy        1.0000       1.0000        1.0\n\nFrom the result, we can see SVM does great job in classifying wine classes from the data set. This model has high accuracy rate and Kappa value.\nVerify my assumption\n\n\nsupportvectors<-SVMTrain[Wine_SVM$finalModel@SVindex,]\nggplot(data=SVMTest, mapping = aes(x=Proline,y=Color.intensity,color=class))+\n  geom_point(alpha=0.5)+\n  geom_point(data=svmtestpred, mapping = aes(x=Proline,y=Color.intensity, color=prediction),shape=6,size=3)+\n  geom_point(data=supportvectors, mapping = aes(x=Proline,y=Color.intensity),shape=4,size=4)+\n  theme(legend.title = element_blank())+ggtitle(\"SVM Demonstration\")\n\n\n\n\nBased on SVM Demonstration plot, variables Proline and Color Intensity are not the only two variables SVM takes into consideration of determining wine types. We can see there are lots of Xs are marked outside of triangels, which means that pridictions and actual results are not matach.\nSVM Applications\nThis is a powerful machine learning algorithm that can be used for classification. From the process result, we understand how well this model determining the wine classes. The machine learning method also can be used in auditing or banking system to pridect going concern issue or bankrupt issues.\n\nhttps://towardsdatascience.com/support-vector-machine-python-example-d67d9b63f1c8↩︎\nhttps://archive.ics.uci.edu/ml/datasets/wine↩︎\n",
      "last_modified": "2021-12-08T21:19:18-06:00"
    },
    {
      "path": "index.html",
      "title": "Whitney Chen",
      "author": [],
      "contents": "\n\n          \n          \n          \n          \n          Whitney Chen\n          \n          \n          Home\n          About\n          Resume\n          \n          \n          Projects\n           \n          ▾\n          \n          \n          R-Squared\n          Machine Learning\n          Final Project\n          \n          \n          ☰\n          \n          \n      \n        \n          \n            Whitney Chen\n          \n          \n            \n              Hey, there! Welcome to my website.\n            \n            \n              Hey, there! Welcome to my website.\n            \n          \n\n          \n            \n              \n                  \n                    \n                      LinkedIn\n                    \n                  \n                \n                                \n                  \n                    \n                      GitHub\n                    \n                  \n                \n                                \n                  \n                    \n                      Email\n                    \n                  \n                \n                              \n          \n\n          \n            \n              \n                                \n                  \n                    LinkedIn\n                  \n                \n                                \n                  \n                    GitHub\n                  \n                \n                                \n                  \n                    Email\n                  \n                \n                              \n            \n          \n        \n      \n    \n\n    \n    \n    ",
      "last_modified": "2021-12-08T21:37:57-06:00"
    },
    {
      "path": "ML.html",
      "title": "Machine Learning",
      "description": "K-Nearest Neighbor\n",
      "author": [],
      "contents": "\n\nContents\nWhat is KNN?\nHow to determine?\nProcesing data\nResults\n\nApply to Accounting Area\n\nWhat is KNN?\nIt is a type of machine learning model that helps to classify the variables. In other words, Knn can determine the characteristic of an object by comparing some objects closely similar to it.\nHow to determine?\nWe will use Tips data1 to predict and classify the sex of customers based on other variables collected in the data set.\nProcesing data\nFirst we split the data into training and testing group, then build Knn model using the training set.\n\n\ntrainIndex <- createDataPartition(tips$sex, p = .6, list = FALSE, times = 1)\nKnnTrain <- tips[ trainIndex,]\nKnnTest  <- tips[-trainIndex,]\n\n# train Knn model with training dataset\nknn_model <- train(\n  sex ~., \n  data = KnnTrain, \n  method = \"knn\",\n  trControl = trainControl(\"cv\", number = 10),\n  preProcess = c(\"center\",\"scale\"),\n  tuneLength = 10\n  )\nknn_model\n\n\nk-Nearest Neighbors \n\n148 samples\n  6 predictor\n  2 classes: 'Female', 'Male' \n\nPre-processing: centered (8), scaled (8) \nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 134, 134, 133, 133, 133, 133, ... \nResampling results across tuning parameters:\n\n  k   Accuracy   Kappa       \n   5  0.5952976   0.081611791\n   7  0.5829762   0.081696268\n   9  0.5686310  -0.006916227\n  11  0.6305357   0.161294824\n  13  0.6514286   0.197656167\n  15  0.6509524   0.192417042\n  17  0.6038095   0.058281225\n  19  0.6323810   0.155596582\n  21  0.6376190   0.149907760\n  23  0.6519048   0.180853903\n\nAccuracy was used to select the optimal model using the\n largest value.\nThe final value used for the model was k = 23.\n\n\n\n\nAs shown above, when comparing to 17 nearest neighbors, Knn model can generate the best result. Next step is making prediction using testing data\n\n\npredictions <- predict(knn_model,KnnTest)\n\n# compute the prediction error\nconfusionMatrix(predictions, factor(KnnTest$sex))\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Female Male\n    Female     10    9\n    Male       24   53\n                                          \n               Accuracy : 0.6562          \n                 95% CI : (0.5523, 0.7502)\n    No Information Rate : 0.6458          \n    P-Value [Acc > NIR] : 0.46165         \n                                          \n                  Kappa : 0.1654          \n                                          \n Mcnemar's Test P-Value : 0.01481         \n                                          \n            Sensitivity : 0.2941          \n            Specificity : 0.8548          \n         Pos Pred Value : 0.5263          \n         Neg Pred Value : 0.6883          \n             Prevalence : 0.3542          \n         Detection Rate : 0.1042          \n   Detection Prevalence : 0.1979          \n      Balanced Accuracy : 0.5745          \n                                          \n       'Positive' Class : Female          \n                                          \n\nResults\nAccording to the confusion matrix, the value of both accuracy and Kappa are low. Knn model did a okay job on classifying the sex of customers based on the characteristics of neighbors. However, this model may not be the best for this data set.\nApply to Accounting Area\nK-Nearest Neighbor machine learning algorithm is useful in predicting bankruptcy and fraudulent transactions. With the model being well trained, auditors can easily forecasting whether or not the company is approaching bankruptcy or have fraudulent activities.\n\nhttps://raw.githubusercontent.com/Professor-Hunt/ACC8143/main/data/tips.rda↩︎\n",
      "last_modified": "2021-12-08T21:19:20-06:00"
    },
    {
      "path": "R-Squared.html",
      "title": "R-Squared",
      "description": "A Different View of R-squared in Data Analytics\n",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\nIssue of using R-squared\nAs taught in my Statistic class, R-squared is an important value to look for in order to find the fitness of the regression model. However, the validity of the R-squared from generated model is unknown to us. If the R-squared provided is not reliable, the results derived from the model will be misled and incorrectly interpreted. Therefore, R-squared should be cautiously used when testing the fitness of a model.\nR-squared does not measure goodness of fit 1\nIt can be arbitrarily low when the model is completely correct.* By making\\(σ^2\\) large, we drive R-squared towards 0, even when every assumption of the simple linear regression model is correct in every particular.\nWhat is \\(σ^2\\)? When we perform linear regression, we assume our model almost predicts our dependent variable. The difference between “almost” and “exact” is assumed to be a draw from a Normal distribution with mean 0 and some variance we call \\(σ^2\\).\nThis statement is easy enough to demonstrate. The way we do it here is to create a function that (1) generates data meeting the assumptions of simple linear regression (independent observations, normally distributed errors with constant variance), (2) fits a simple linear model to the data, and (3) reports the R-squared. Notice the only parameter for sake of simplicity is sigma. We then “apply” this function to a series of increasing \\(σ\\) values and plot the results.\n\n\nr2.0 <- function(sig){\n  # our predictor\n  x <- seq(1,10,length.out = 100)   \n  # our response; a function of x plus some random noise\n  y <- 2 + 1.2*x + rnorm(100,0,sd = sig) \n  # print the R-squared value\n  summary(lm(y ~ x))$r.squared          \n}\nsigmas <- seq(0.5,20,length.out = 20)\n # apply our function to a series of sigma values\nrout <- sapply(sigmas, r2.0)            \nplot(rout ~ sigmas, type=\"b\")\n\n\n\n\nR-squared tanks hard with increasing sigma, even though the model is completely correct in every respect.\nR-squared can be arbitrarily close to 1 when the model is totally wrong2\nThe point being made is that R-squared does not measure goodness of fit.\n\n\nset.seed(1)\n# our predictor is data from an exponential distribution\nx <- rexp(50,rate=0.005)\n# non-linear data generation\ny <- (x-1)^2 * runif(50, min=0.8, max=1.2) \n# clearly non-linear\nplot(x,y)             \n\n\n\n\n\n\nsummary(lm(y ~ x))$r.squared\n\n\n[1] 0.8485146\n\nIt’s very high at about 0.85, but the model is completely wrong. Using R-squared to justify the “goodness” of our model in this instance would be a mistake. Hopefully one would plot the data first and recognize that a simple linear regression in this case would be inappropriate.\nSuggestion\nIn addition to what explained above, R-squared does not either necessarily increase when assumptions are better satisfied or measure how one variable explains another. When we try to measure the fitness of regression model, adjusted R-squared provides a good measure about the model.\n\nhttps://data.library.virginia.edu/is-r-squared-useless/↩︎\nhttps://data.library.virginia.edu/is-r-squared-useless/↩︎\n",
      "last_modified": "2021-12-08T21:19:21-06:00"
    },
    {
      "path": "Resume.html",
      "title": "Resume",
      "description": "Work and Education Experiences\n",
      "author": [],
      "contents": "\n\nWhitney Chen\nEmail: wc735@msstate.edu\nPhone: (662)801-9876\nLinkedin\n\nEducation\nMaster of Professional Accounting – Mississippi State University, Starkville, MS, May 2022\nBachelor of Accountancy – Mississippi State University, Starkville, MS, May 2021\nMinor: Business Analytics\nExperiences\nGraduate Teaching Assistant | Mississippi State University, College of Business – Starkville, MS | 06/2021 – Current\nSupport professor in implementing rigorous teaching and learning experiences.\nAssign, collect, and grade student’s work accounting to processes outline by professor and department.\nFollow established course outline to prepare and convey information and enhance understanding of materials.\nAcademic Tutor | Mississippi State University, Athletic Academic Center – Starkville, MS | 07/2020 – 04/2021\nSupported student-athlete learning through virtual instruction.\nWrote detailed summaries about each tutoring session and uploaded them to the appropriate platform.\nContacted the tutorial supervisor about any concerns.\nCollege Coach | Mississippi State University, Student Support Service Center – Starkville, MS | 08/2019 – 04/2021\nLead team of four peer mentors in designing weekly activities for 10 students with intellectual disorders to improve their independent skills.\nCollaborated with 20 team members and four graduate assistants to execute a student behavioral experiment.\nCommunicated performances of the assigned students to program’s director and parents on a weekly basis.\nVice President of Community Service | Accounting and Finance Student Society – Starkville, MS | 08/2019 – 05/2020\nCollaborated with four officers to plan activities and made organizational decisions.\nOrganized and coordinated two community service events for 25 members each semester.\nMember | Beta Alpha Psi | Mississippi State University | 07/2019 – Current\nProctor Accounting Departmental exams.\nImprove vocational skills through professional meetings, workshops, and networking events.\nSkills\nMastery of Microsoft Office Suite\nR Studio\nCertified Microsoft Office Excel Specialist\nAudit Command Language (ACL)\nLanguages\nWorking proficiency in French\nFluent in Mandarin\n\n\n\n",
      "last_modified": "2021-12-08T21:19:21-06:00"
    }
  ],
  "collections": []
}
